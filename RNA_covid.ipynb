{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/martinoni/mae5904-rna/3e4cc70aab3f4f7ebda4c90f425a77a7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from comet_ml import Experiment\n",
    "experiment = Experiment(\n",
    "    api_key=\"91nnAun2dj21K2NJIR8vmC3Dk\",\n",
    "    project_name=\"mae5904-rna\",\n",
    "    workspace=\"martinoni\",\n",
    ")\n",
    "from pandas import read_csv, get_dummies, to_datetime\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from numpy import abs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martinoni/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (16) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>resultadoTeste</th>\n",
       "      <th>sexo</th>\n",
       "      <th>idade</th>\n",
       "      <th>Assintomatico</th>\n",
       "      <th>Coriza</th>\n",
       "      <th>Dispneia</th>\n",
       "      <th>DistGustativos</th>\n",
       "      <th>DistOlfativos</th>\n",
       "      <th>DorDeCabeca</th>\n",
       "      <th>DorDeGarganta</th>\n",
       "      <th>Febre</th>\n",
       "      <th>Tosse</th>\n",
       "      <th>Outros</th>\n",
       "      <th>profissionalSaude</th>\n",
       "      <th>dataNotificacao</th>\n",
       "      <th>municipioIBGE</th>\n",
       "      <th>municipioNotificacaoIBGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Não</td>\n",
       "      <td>2020-09-30</td>\n",
       "      <td>3524709</td>\n",
       "      <td>3524709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Não</td>\n",
       "      <td>2020-10-06</td>\n",
       "      <td>3513504</td>\n",
       "      <td>3513504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Não</td>\n",
       "      <td>2020-09-30</td>\n",
       "      <td>3504107</td>\n",
       "      <td>3504107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Não</td>\n",
       "      <td>2020-10-08</td>\n",
       "      <td>3522307</td>\n",
       "      <td>3522307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Não</td>\n",
       "      <td>2020-10-15</td>\n",
       "      <td>3509007</td>\n",
       "      <td>3550308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280697</th>\n",
       "      <td>280698</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Não</td>\n",
       "      <td>2020-09-18</td>\n",
       "      <td>3550308</td>\n",
       "      <td>3550308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280698</th>\n",
       "      <td>280699</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Não</td>\n",
       "      <td>2020-10-20</td>\n",
       "      <td>3549805</td>\n",
       "      <td>3549805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280699</th>\n",
       "      <td>280700</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Não</td>\n",
       "      <td>2020-10-20</td>\n",
       "      <td>3538709</td>\n",
       "      <td>3538709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280700</th>\n",
       "      <td>280701</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Não</td>\n",
       "      <td>2020-10-13</td>\n",
       "      <td>3505708</td>\n",
       "      <td>3505708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280701</th>\n",
       "      <td>280702</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Não</td>\n",
       "      <td>2020-10-16</td>\n",
       "      <td>3538709</td>\n",
       "      <td>3538709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280702 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0 resultadoTeste       sexo  idade  Assintomatico  Coriza  \\\n",
       "0                1       Negativo   Feminino     53              0       0   \n",
       "1                2       Negativo   Feminino     18              0       0   \n",
       "2                3       Negativo  Masculino     28              0       1   \n",
       "3                4       Positivo  Masculino     27              0       0   \n",
       "4                5       Negativo  Masculino     54              0       0   \n",
       "...            ...            ...        ...    ...            ...     ...   \n",
       "280697      280698       Negativo  Masculino     77              0       1   \n",
       "280698      280699       Negativo  Masculino     20              0       0   \n",
       "280699      280700       Negativo   Feminino     35              0       0   \n",
       "280700      280701       Negativo  Masculino     33              0       1   \n",
       "280701      280702       Negativo  Masculino      3              0       0   \n",
       "\n",
       "        Dispneia  DistGustativos  DistOlfativos  DorDeCabeca  DorDeGarganta  \\\n",
       "0              1               0              0            0              0   \n",
       "1              0               0              0            1              1   \n",
       "2              0               0              0            1              1   \n",
       "3              0               0              0            0              0   \n",
       "4              0               0              0            0              0   \n",
       "...          ...             ...            ...          ...            ...   \n",
       "280697         0               0              0            1              0   \n",
       "280698         0               0              0            0              1   \n",
       "280699         0               1              1            0              0   \n",
       "280700         1               1              1            1              1   \n",
       "280701         0               0              0            0              1   \n",
       "\n",
       "        Febre  Tosse  Outros profissionalSaude dataNotificacao municipioIBGE  \\\n",
       "0           0      0       0               Não      2020-09-30       3524709   \n",
       "1           1      1       0               Não      2020-10-06       3513504   \n",
       "2           1      0       0               Não      2020-09-30       3504107   \n",
       "3           0      1       1               Não      2020-10-08       3522307   \n",
       "4           0      0       1               Não      2020-10-15       3509007   \n",
       "...       ...    ...     ...               ...             ...           ...   \n",
       "280697      1      1       1               Não      2020-09-18       3550308   \n",
       "280698      0      0       0               Não      2020-10-20       3549805   \n",
       "280699      0      1       1               Não      2020-10-20       3538709   \n",
       "280700      1      1       0               Não      2020-10-13       3505708   \n",
       "280701      1      1       0               Não      2020-10-16       3538709   \n",
       "\n",
       "        municipioNotificacaoIBGE  \n",
       "0                        3524709  \n",
       "1                        3513504  \n",
       "2                        3504107  \n",
       "3                        3522307  \n",
       "4                        3550308  \n",
       "...                          ...  \n",
       "280697                   3550308  \n",
       "280698                   3549805  \n",
       "280699                   3538709  \n",
       "280700                   3505708  \n",
       "280701                   3538709  \n",
       "\n",
       "[280702 rows x 18 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados = read_csv('dados.csv', sep=',', encoding='latin-1')\n",
    "dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordenação dos dados por data de notificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resultadoTeste</th>\n",
       "      <th>sexo</th>\n",
       "      <th>idade</th>\n",
       "      <th>Assintomatico</th>\n",
       "      <th>Coriza</th>\n",
       "      <th>Dispneia</th>\n",
       "      <th>DistGustativos</th>\n",
       "      <th>DistOlfativos</th>\n",
       "      <th>DorDeCabeca</th>\n",
       "      <th>DorDeGarganta</th>\n",
       "      <th>Febre</th>\n",
       "      <th>Tosse</th>\n",
       "      <th>Outros</th>\n",
       "      <th>profissionalSaude</th>\n",
       "      <th>dataNotificacao</th>\n",
       "      <th>municipioIBGE</th>\n",
       "      <th>municipioNotificacaoIBGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Positivo</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Não</td>\n",
       "      <td>2020-06-02</td>\n",
       "      <td>3550308</td>\n",
       "      <td>3550308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positivo</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Não</td>\n",
       "      <td>2020-06-02</td>\n",
       "      <td>3550308</td>\n",
       "      <td>3550308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positivo</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Não</td>\n",
       "      <td>2020-06-02</td>\n",
       "      <td>3529401</td>\n",
       "      <td>3547809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positivo</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Não</td>\n",
       "      <td>2020-06-02</td>\n",
       "      <td>3509700</td>\n",
       "      <td>3509700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Negativo</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Não</td>\n",
       "      <td>2020-06-02</td>\n",
       "      <td>3512407</td>\n",
       "      <td>3512407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280697</th>\n",
       "      <td>Negativo</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Não</td>\n",
       "      <td>2020-11-03</td>\n",
       "      <td>3513702</td>\n",
       "      <td>3513702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280698</th>\n",
       "      <td>Positivo</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Não</td>\n",
       "      <td>2020-11-03</td>\n",
       "      <td>3536505</td>\n",
       "      <td>3536505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280699</th>\n",
       "      <td>Negativo</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Não</td>\n",
       "      <td>2020-11-03</td>\n",
       "      <td>3513702</td>\n",
       "      <td>3513702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280700</th>\n",
       "      <td>Negativo</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Não</td>\n",
       "      <td>2020-11-03</td>\n",
       "      <td>3539301</td>\n",
       "      <td>3539301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280701</th>\n",
       "      <td>Positivo</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Não</td>\n",
       "      <td>2020-11-03</td>\n",
       "      <td>3550308</td>\n",
       "      <td>3550308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280702 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       resultadoTeste       sexo  idade  Assintomatico  Coriza  Dispneia  \\\n",
       "0            Positivo   Feminino     22              0       0         1   \n",
       "1            Positivo  Masculino     66              0       0         0   \n",
       "2            Positivo  Masculino     45              0       0         0   \n",
       "3            Positivo   Feminino     19              0       0         0   \n",
       "4            Negativo   Feminino     38              0       0         0   \n",
       "...               ...        ...    ...            ...     ...       ...   \n",
       "280697       Negativo   Feminino     50              0       0         0   \n",
       "280698       Positivo  Masculino     27              0       0         0   \n",
       "280699       Negativo   Feminino     89              0       0         1   \n",
       "280700       Negativo  Masculino     44              0       1         0   \n",
       "280701       Positivo  Masculino     21              0       0         0   \n",
       "\n",
       "        DistGustativos  DistOlfativos  DorDeCabeca  DorDeGarganta  Febre  \\\n",
       "0                    1              1            0              0      0   \n",
       "1                    0              0            0              0      0   \n",
       "2                    0              0            0              0      0   \n",
       "3                    0              0            0              1      1   \n",
       "4                    0              0            0              1      0   \n",
       "...                ...            ...          ...            ...    ...   \n",
       "280697               0              0            0              1      0   \n",
       "280698               0              0            0              0      0   \n",
       "280699               0              0            0              0      1   \n",
       "280700               0              0            0              1      1   \n",
       "280701               0              0            1              0      0   \n",
       "\n",
       "        Tosse  Outros profissionalSaude dataNotificacao municipioIBGE  \\\n",
       "0           0       1               Não      2020-06-02       3550308   \n",
       "1           1       1               Não      2020-06-02       3550308   \n",
       "2           1       1               Não      2020-06-02       3529401   \n",
       "3           1       1               Não      2020-06-02       3509700   \n",
       "4           1       1               Não      2020-06-02       3512407   \n",
       "...       ...     ...               ...             ...           ...   \n",
       "280697      1       0               Não      2020-11-03       3513702   \n",
       "280698      1       0               Não      2020-11-03       3536505   \n",
       "280699      0       0               Não      2020-11-03       3513702   \n",
       "280700      0       0               Não      2020-11-03       3539301   \n",
       "280701      0       1               Não      2020-11-03       3550308   \n",
       "\n",
       "        municipioNotificacaoIBGE  \n",
       "0                        3550308  \n",
       "1                        3550308  \n",
       "2                        3547809  \n",
       "3                        3509700  \n",
       "4                        3512407  \n",
       "...                          ...  \n",
       "280697                   3513702  \n",
       "280698                   3536505  \n",
       "280699                   3513702  \n",
       "280700                   3539301  \n",
       "280701                   3550308  \n",
       "\n",
       "[280702 rows x 17 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados = dados.drop('Unnamed: 0', axis=1)\n",
    "dados['dataNotificacao'] = to_datetime(dados.dataNotificacao)\n",
    "dados = dados.sort_values('dataNotificacao', ignore_index=True)\n",
    "dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quais variáveis podemos usar na nossa rede neural?\n",
    "\n",
    "* Fatores (input)\n",
    "    1. Sexo\n",
    "    2. Sintomas (Assintomático, Coriza, Dispneia...)\n",
    "    3. municipioIBGE\n",
    "    4. municipioNotificacaoIBGE\n",
    "    \n",
    "    \n",
    "* Escalar (input)\n",
    "    1. idade\n",
    "    \n",
    "    \n",
    "\n",
    "* Variável Resposta (output)\n",
    "    1. resultadoTeste (1=Positivo; 0=Negativo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = dados.drop(['dataNotificacao', 'municipioNotificacaoIBGE', 'municipioIBGE'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_dummy = get_dummies(dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idade</th>\n",
       "      <th>Assintomatico</th>\n",
       "      <th>Coriza</th>\n",
       "      <th>Dispneia</th>\n",
       "      <th>DistGustativos</th>\n",
       "      <th>DistOlfativos</th>\n",
       "      <th>DorDeCabeca</th>\n",
       "      <th>DorDeGarganta</th>\n",
       "      <th>Febre</th>\n",
       "      <th>Tosse</th>\n",
       "      <th>Outros</th>\n",
       "      <th>resultadoTeste_Negativo</th>\n",
       "      <th>resultadoTeste_Positivo</th>\n",
       "      <th>sexo_Feminino</th>\n",
       "      <th>sexo_Masculino</th>\n",
       "      <th>profissionalSaude_Não</th>\n",
       "      <th>profissionalSaude_Sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280697</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280698</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280699</th>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280700</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280701</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280702 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        idade  Assintomatico  Coriza  Dispneia  DistGustativos  DistOlfativos  \\\n",
       "0          22              0       0         1               1              1   \n",
       "1          66              0       0         0               0              0   \n",
       "2          45              0       0         0               0              0   \n",
       "3          19              0       0         0               0              0   \n",
       "4          38              0       0         0               0              0   \n",
       "...       ...            ...     ...       ...             ...            ...   \n",
       "280697     50              0       0         0               0              0   \n",
       "280698     27              0       0         0               0              0   \n",
       "280699     89              0       0         1               0              0   \n",
       "280700     44              0       1         0               0              0   \n",
       "280701     21              0       0         0               0              0   \n",
       "\n",
       "        DorDeCabeca  DorDeGarganta  Febre  Tosse  Outros  \\\n",
       "0                 0              0      0      0       1   \n",
       "1                 0              0      0      1       1   \n",
       "2                 0              0      0      1       1   \n",
       "3                 0              1      1      1       1   \n",
       "4                 0              1      0      1       1   \n",
       "...             ...            ...    ...    ...     ...   \n",
       "280697            0              1      0      1       0   \n",
       "280698            0              0      0      1       0   \n",
       "280699            0              0      1      0       0   \n",
       "280700            0              1      1      0       0   \n",
       "280701            1              0      0      0       1   \n",
       "\n",
       "        resultadoTeste_Negativo  resultadoTeste_Positivo  sexo_Feminino  \\\n",
       "0                             0                        1              1   \n",
       "1                             0                        1              0   \n",
       "2                             0                        1              0   \n",
       "3                             0                        1              1   \n",
       "4                             1                        0              1   \n",
       "...                         ...                      ...            ...   \n",
       "280697                        1                        0              1   \n",
       "280698                        0                        1              0   \n",
       "280699                        1                        0              1   \n",
       "280700                        1                        0              0   \n",
       "280701                        0                        1              0   \n",
       "\n",
       "        sexo_Masculino  profissionalSaude_Não  profissionalSaude_Sim  \n",
       "0                    0                      1                      0  \n",
       "1                    1                      1                      0  \n",
       "2                    1                      1                      0  \n",
       "3                    0                      1                      0  \n",
       "4                    0                      1                      0  \n",
       "...                ...                    ...                    ...  \n",
       "280697               0                      1                      0  \n",
       "280698               1                      1                      0  \n",
       "280699               0                      1                      0  \n",
       "280700               1                      1                      0  \n",
       "280701               1                      1                      0  \n",
       "\n",
       "[280702 rows x 17 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dados_dummy.drop('resultadoTeste_Positivo', axis=1).drop('resultadoTeste_Negativo', axis=1)\n",
    "y = dados_dummy[['resultadoTeste_Positivo']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensões de X: (280702, 15)\n",
      "Dimensões de y: (280702, 1)\n"
     ]
    }
   ],
   "source": [
    "print('Dimensões de X: ' + str(X.shape))\n",
    "print('Dimensões de y: ' + str(y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arquitetura do modelo\n",
    "\n",
    "# Gráfico\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Resultar(shape, n_h=128, batch_size=128):\n",
    "    input = Input(shape=shape, name='Input')\n",
    "    X = Dense(n_h, activation='sigmoid', \n",
    "              name='Hidden_Layer_with_%d_units' % n_h)(input)\n",
    "    X = Dense(1, activation='sigmoid', \n",
    "             name='Probability_Covid')(X)\n",
    "    output = X\n",
    "    \n",
    "    model = Model(inputs = input, outputs = output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (InputLayer)           [(None, 15)]              0         \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_with_8_units (D (None, 8)                 128       \n",
      "_________________________________________________________________\n",
      "Probability_Covid (Dense)    (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 137\n",
      "Trainable params: 137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Resultar(shape = (X.shape[1]), n_h=8)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separação da base de dados em treino e teste\n",
    "\n",
    "# Gráfico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_max = (4*X.shape[0])//5\n",
    "X_train = X[:index_max]\n",
    "X_test = X[index_max+1:]\n",
    "y_train = y[:index_max]\n",
    "y_test = y[index_max+1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problemas computacionais\n",
    "\n",
    "- Treino local ou na cloud?\n",
    "- CPU ou GPU?\n",
    "- Alocação de memória RAM\n",
    "- Alocação de VRAM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dados\n",
    "del dados_dummy\n",
    "del X\n",
    "del y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escolha de otimizador e função de perda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = Adam(), loss = BinaryCrossentropy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "epochs = 500\n",
    "\n",
    "params={\n",
    "    \"batch_size\":batch_size,\n",
    "    \"epochs\":epochs}\n",
    "experiment.log_parameters(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Ignoring automatic log_parameter('verbose') because 'keras:verbose' is in COMET_LOGGING_PARAMETERS_IGNORE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.7045 - val_loss: 0.6176\n",
      "Epoch 2/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6430 - val_loss: 0.6100\n",
      "Epoch 3/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6367 - val_loss: 0.5989\n",
      "Epoch 4/500\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.6277 - val_loss: 0.5881\n",
      "Epoch 5/500\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.6209 - val_loss: 0.5831\n",
      "Epoch 6/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6181 - val_loss: 0.5805\n",
      "Epoch 7/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6169 - val_loss: 0.5802\n",
      "Epoch 8/500\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.6163 - val_loss: 0.5795\n",
      "Epoch 9/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6160 - val_loss: 0.5799\n",
      "Epoch 10/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6156 - val_loss: 0.5791\n",
      "Epoch 11/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6154 - val_loss: 0.5783\n",
      "Epoch 12/500\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5772\n",
      "Epoch 13/500\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5788\n",
      "Epoch 14/500\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.6149 - val_loss: 0.5767\n",
      "Epoch 15/500\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.6147 - val_loss: 0.5767\n",
      "Epoch 16/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6147 - val_loss: 0.5764\n",
      "Epoch 17/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6146 - val_loss: 0.5777\n",
      "Epoch 18/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6145 - val_loss: 0.5787\n",
      "Epoch 19/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6143 - val_loss: 0.5773\n",
      "Epoch 20/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6142 - val_loss: 0.5783\n",
      "Epoch 21/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6142 - val_loss: 0.5793\n",
      "Epoch 22/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6141 - val_loss: 0.5781\n",
      "Epoch 23/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6140 - val_loss: 0.5769\n",
      "Epoch 24/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6140 - val_loss: 0.5769\n",
      "Epoch 25/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6139 - val_loss: 0.5763\n",
      "Epoch 26/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6139 - val_loss: 0.5753\n",
      "Epoch 27/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6138 - val_loss: 0.5758\n",
      "Epoch 28/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6138 - val_loss: 0.5769\n",
      "Epoch 29/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6137 - val_loss: 0.5768\n",
      "Epoch 30/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6138 - val_loss: 0.5767\n",
      "Epoch 31/500\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.6137 - val_loss: 0.5744\n",
      "Epoch 32/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6137 - val_loss: 0.5789\n",
      "Epoch 33/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6136 - val_loss: 0.5737\n",
      "Epoch 34/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6136 - val_loss: 0.5776\n",
      "Epoch 35/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6135 - val_loss: 0.5746\n",
      "Epoch 36/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6135 - val_loss: 0.5768\n",
      "Epoch 37/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6135 - val_loss: 0.5774\n",
      "Epoch 38/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6135 - val_loss: 0.5778\n",
      "Epoch 39/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6135 - val_loss: 0.5772\n",
      "Epoch 40/500\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.6135 - val_loss: 0.5757\n",
      "Epoch 41/500\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.6134 - val_loss: 0.5751\n",
      "Epoch 42/500\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.6134 - val_loss: 0.5769\n",
      "Epoch 43/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6133 - val_loss: 0.5757\n",
      "Epoch 44/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6133 - val_loss: 0.5752\n",
      "Epoch 45/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6132 - val_loss: 0.5757\n",
      "Epoch 46/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6132 - val_loss: 0.5761\n",
      "Epoch 47/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6131 - val_loss: 0.5756\n",
      "Epoch 48/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6132 - val_loss: 0.5739\n",
      "Epoch 49/500\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.6131 - val_loss: 0.5763\n",
      "Epoch 50/500\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.6130 - val_loss: 0.5779\n",
      "Epoch 51/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6130 - val_loss: 0.5757\n",
      "Epoch 52/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6130 - val_loss: 0.5753\n",
      "Epoch 53/500\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.6129 - val_loss: 0.5760\n",
      "Epoch 54/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6129 - val_loss: 0.5770\n",
      "Epoch 55/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6128 - val_loss: 0.5760\n",
      "Epoch 56/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6128 - val_loss: 0.5787\n",
      "Epoch 57/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6129 - val_loss: 0.5780\n",
      "Epoch 58/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6128 - val_loss: 0.5765\n",
      "Epoch 59/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6128 - val_loss: 0.5750\n",
      "Epoch 60/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6127 - val_loss: 0.5747\n",
      "Epoch 61/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6127 - val_loss: 0.5776\n",
      "Epoch 62/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6127 - val_loss: 0.5747\n",
      "Epoch 63/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6128 - val_loss: 0.5749\n",
      "Epoch 64/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6126 - val_loss: 0.5755\n",
      "Epoch 65/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6127 - val_loss: 0.5766\n",
      "Epoch 66/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6126 - val_loss: 0.5755\n",
      "Epoch 67/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6126 - val_loss: 0.5742\n",
      "Epoch 68/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6126 - val_loss: 0.5741\n",
      "Epoch 69/500\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.6126 - val_loss: 0.5753\n",
      "Epoch 70/500\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.6125 - val_loss: 0.5755\n",
      "Epoch 71/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6126 - val_loss: 0.5759\n",
      "Epoch 72/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6126 - val_loss: 0.5752\n",
      "Epoch 73/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6126 - val_loss: 0.5750\n",
      "Epoch 74/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6126 - val_loss: 0.5755\n",
      "Epoch 75/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6125 - val_loss: 0.5753\n",
      "Epoch 76/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6125 - val_loss: 0.5766\n",
      "Epoch 77/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6125 - val_loss: 0.5745\n",
      "Epoch 78/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6124 - val_loss: 0.5743\n",
      "Epoch 79/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6125 - val_loss: 0.5760\n",
      "Epoch 80/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6124 - val_loss: 0.5768\n",
      "Epoch 81/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6124 - val_loss: 0.5737\n",
      "Epoch 82/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6124 - val_loss: 0.5743\n",
      "Epoch 83/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6124 - val_loss: 0.5760\n",
      "Epoch 84/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6123 - val_loss: 0.5760\n",
      "Epoch 85/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6123 - val_loss: 0.5736\n",
      "Epoch 86/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6123 - val_loss: 0.5738\n",
      "Epoch 87/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6123 - val_loss: 0.5764\n",
      "Epoch 88/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6123 - val_loss: 0.5737\n",
      "Epoch 89/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6123 - val_loss: 0.5741\n",
      "Epoch 90/500\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.6123 - val_loss: 0.5763\n",
      "Epoch 91/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6123 - val_loss: 0.5763\n",
      "Epoch 92/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6123 - val_loss: 0.5743\n",
      "Epoch 93/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6122 - val_loss: 0.5740\n",
      "Epoch 94/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6122 - val_loss: 0.5748\n",
      "Epoch 95/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6121 - val_loss: 0.5736\n",
      "Epoch 96/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6122 - val_loss: 0.5757\n",
      "Epoch 97/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6122 - val_loss: 0.5741\n",
      "Epoch 98/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6121 - val_loss: 0.5768\n",
      "Epoch 99/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6121 - val_loss: 0.5744\n",
      "Epoch 100/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6121 - val_loss: 0.5734\n",
      "Epoch 101/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6121 - val_loss: 0.5728\n",
      "Epoch 102/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6122 - val_loss: 0.5757\n",
      "Epoch 103/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6122 - val_loss: 0.5754\n",
      "Epoch 104/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6120 - val_loss: 0.5739\n",
      "Epoch 105/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6121 - val_loss: 0.5753\n",
      "Epoch 106/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6121 - val_loss: 0.5761\n",
      "Epoch 107/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6120 - val_loss: 0.5743\n",
      "Epoch 108/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6121 - val_loss: 0.5742\n",
      "Epoch 109/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6120 - val_loss: 0.5730\n",
      "Epoch 110/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6120 - val_loss: 0.5732\n",
      "Epoch 111/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6120 - val_loss: 0.5751\n",
      "Epoch 112/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6120 - val_loss: 0.5764\n",
      "Epoch 113/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6120 - val_loss: 0.5744\n",
      "Epoch 114/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6119 - val_loss: 0.5740\n",
      "Epoch 115/500\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.6120 - val_loss: 0.5749\n",
      "Epoch 116/500\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.6120 - val_loss: 0.5737\n",
      "Epoch 117/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6120 - val_loss: 0.5753\n",
      "Epoch 118/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6119 - val_loss: 0.5762\n",
      "Epoch 119/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6120 - val_loss: 0.5753\n",
      "Epoch 120/500\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.6119 - val_loss: 0.5759\n",
      "Epoch 121/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6119 - val_loss: 0.5743\n",
      "Epoch 122/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6119 - val_loss: 0.5738\n",
      "Epoch 123/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6119 - val_loss: 0.5735\n",
      "Epoch 124/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6119 - val_loss: 0.5734\n",
      "Epoch 125/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6119 - val_loss: 0.5778\n",
      "Epoch 126/500\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.6120 - val_loss: 0.5735\n",
      "Epoch 127/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6119 - val_loss: 0.5758\n",
      "Epoch 128/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6119 - val_loss: 0.5741\n",
      "Epoch 129/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6118 - val_loss: 0.5742\n",
      "Epoch 130/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6118 - val_loss: 0.5760\n",
      "Epoch 131/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6119 - val_loss: 0.5745\n",
      "Epoch 132/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6118 - val_loss: 0.5737\n",
      "Epoch 133/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6118 - val_loss: 0.5735\n",
      "Epoch 134/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6118 - val_loss: 0.5737\n",
      "Epoch 135/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6119 - val_loss: 0.5751\n",
      "Epoch 136/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6119 - val_loss: 0.5763\n",
      "Epoch 137/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6118 - val_loss: 0.5725\n",
      "Epoch 138/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6118 - val_loss: 0.5741\n",
      "Epoch 139/500\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.6118 - val_loss: 0.5769\n",
      "Epoch 140/500\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.6119 - val_loss: 0.5736\n",
      "Epoch 141/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6118 - val_loss: 0.5739\n",
      "Epoch 142/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6117 - val_loss: 0.5773\n",
      "Epoch 143/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6118 - val_loss: 0.5744\n",
      "Epoch 144/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6118 - val_loss: 0.5736\n",
      "Epoch 145/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6117 - val_loss: 0.5735\n",
      "Epoch 146/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6118 - val_loss: 0.5757\n",
      "Epoch 147/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6118 - val_loss: 0.5746\n",
      "Epoch 148/500\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.6118 - val_loss: 0.5730\n",
      "Epoch 149/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6117 - val_loss: 0.5777\n",
      "Epoch 150/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6118 - val_loss: 0.5739\n",
      "Epoch 151/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6117 - val_loss: 0.5734\n",
      "Epoch 152/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6118 - val_loss: 0.5751\n",
      "Epoch 153/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6118 - val_loss: 0.5742\n",
      "Epoch 154/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6118 - val_loss: 0.5742\n",
      "Epoch 155/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6117 - val_loss: 0.5738\n",
      "Epoch 156/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6117 - val_loss: 0.5729\n",
      "Epoch 157/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6117 - val_loss: 0.5745\n",
      "Epoch 158/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6118 - val_loss: 0.5743\n",
      "Epoch 159/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6117 - val_loss: 0.5740\n",
      "Epoch 160/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6117 - val_loss: 0.5747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6117 - val_loss: 0.5748\n",
      "Epoch 162/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6117 - val_loss: 0.5738\n",
      "Epoch 163/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6117 - val_loss: 0.5737\n",
      "Epoch 164/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6118 - val_loss: 0.5764\n",
      "Epoch 165/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6118 - val_loss: 0.5746\n",
      "Epoch 166/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6117 - val_loss: 0.5745\n",
      "Epoch 167/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6118 - val_loss: 0.5756\n",
      "Epoch 168/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6117 - val_loss: 0.5757\n",
      "Epoch 169/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6117 - val_loss: 0.5746\n",
      "Epoch 170/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6118 - val_loss: 0.5752\n",
      "Epoch 171/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6118 - val_loss: 0.5746\n",
      "Epoch 172/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6117 - val_loss: 0.5737\n",
      "Epoch 173/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6117 - val_loss: 0.5763\n",
      "Epoch 174/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6117 - val_loss: 0.5746\n",
      "Epoch 175/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6117 - val_loss: 0.5746\n",
      "Epoch 176/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6117 - val_loss: 0.5746\n",
      "Epoch 177/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6117 - val_loss: 0.5727\n",
      "Epoch 178/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6117 - val_loss: 0.5735\n",
      "Epoch 179/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6118 - val_loss: 0.5740\n",
      "Epoch 180/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6117 - val_loss: 0.5733\n",
      "Epoch 181/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6117 - val_loss: 0.5745\n",
      "Epoch 182/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6117 - val_loss: 0.5743\n",
      "Epoch 183/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6118 - val_loss: 0.5751\n",
      "Epoch 184/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6117 - val_loss: 0.5744\n",
      "Epoch 185/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6118 - val_loss: 0.5736\n",
      "Epoch 186/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5721\n",
      "Epoch 187/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6117 - val_loss: 0.5737\n",
      "Epoch 188/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5748\n",
      "Epoch 189/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6117 - val_loss: 0.5736\n",
      "Epoch 190/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6117 - val_loss: 0.5735\n",
      "Epoch 191/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5765\n",
      "Epoch 192/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6117 - val_loss: 0.5740\n",
      "Epoch 193/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6117 - val_loss: 0.5747\n",
      "Epoch 194/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6117 - val_loss: 0.5746\n",
      "Epoch 195/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6117 - val_loss: 0.5725\n",
      "Epoch 196/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6117 - val_loss: 0.5734\n",
      "Epoch 197/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6117 - val_loss: 0.5742\n",
      "Epoch 198/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6117 - val_loss: 0.5740\n",
      "Epoch 199/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5735\n",
      "Epoch 200/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6117 - val_loss: 0.5748\n",
      "Epoch 201/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5739\n",
      "Epoch 202/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6117 - val_loss: 0.5768\n",
      "Epoch 203/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5761\n",
      "Epoch 204/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5724\n",
      "Epoch 205/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6118 - val_loss: 0.5757\n",
      "Epoch 206/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6117 - val_loss: 0.5743\n",
      "Epoch 207/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5758\n",
      "Epoch 208/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6117 - val_loss: 0.5734\n",
      "Epoch 209/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5734\n",
      "Epoch 210/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5740\n",
      "Epoch 211/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5751\n",
      "Epoch 212/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5771\n",
      "Epoch 213/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6117 - val_loss: 0.5728\n",
      "Epoch 214/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6117 - val_loss: 0.5756\n",
      "Epoch 215/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5745\n",
      "Epoch 216/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5743\n",
      "Epoch 217/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6117 - val_loss: 0.5746\n",
      "Epoch 218/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5738\n",
      "Epoch 219/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6117 - val_loss: 0.5740\n",
      "Epoch 220/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5752\n",
      "Epoch 221/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6118 - val_loss: 0.5745\n",
      "Epoch 222/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5745\n",
      "Epoch 223/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5769\n",
      "Epoch 224/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6117 - val_loss: 0.5747\n",
      "Epoch 225/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5740\n",
      "Epoch 226/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5728\n",
      "Epoch 227/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6117 - val_loss: 0.5740\n",
      "Epoch 228/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5730\n",
      "Epoch 229/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5760\n",
      "Epoch 230/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5735\n",
      "Epoch 231/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5740\n",
      "Epoch 232/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5741\n",
      "Epoch 233/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5745\n",
      "Epoch 234/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6117 - val_loss: 0.5753\n",
      "Epoch 235/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5734\n",
      "Epoch 236/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5750\n",
      "Epoch 237/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5745\n",
      "Epoch 238/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5742\n",
      "Epoch 239/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5746\n",
      "Epoch 240/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5737\n",
      "Epoch 241/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6117 - val_loss: 0.5783\n",
      "Epoch 242/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5731\n",
      "Epoch 243/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5737\n",
      "Epoch 244/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5738\n",
      "Epoch 245/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5777\n",
      "Epoch 246/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5782\n",
      "Epoch 247/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5757\n",
      "Epoch 248/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5762\n",
      "Epoch 249/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5753\n",
      "Epoch 250/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5747\n",
      "Epoch 251/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6117 - val_loss: 0.5743\n",
      "Epoch 252/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5748\n",
      "Epoch 253/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5735\n",
      "Epoch 254/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5725\n",
      "Epoch 255/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5740\n",
      "Epoch 256/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5728\n",
      "Epoch 257/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5729\n",
      "Epoch 258/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5734\n",
      "Epoch 259/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5752\n",
      "Epoch 260/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5737\n",
      "Epoch 261/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5755\n",
      "Epoch 262/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5733\n",
      "Epoch 263/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5732\n",
      "Epoch 264/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5757\n",
      "Epoch 265/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5730\n",
      "Epoch 266/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5746\n",
      "Epoch 267/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5752\n",
      "Epoch 268/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5750\n",
      "Epoch 269/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5739\n",
      "Epoch 270/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5764\n",
      "Epoch 271/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5760\n",
      "Epoch 272/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5736\n",
      "Epoch 273/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5724\n",
      "Epoch 274/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5747\n",
      "Epoch 275/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5757\n",
      "Epoch 276/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5733\n",
      "Epoch 277/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5731\n",
      "Epoch 278/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5738\n",
      "Epoch 279/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5732\n",
      "Epoch 280/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5726\n",
      "Epoch 281/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5730\n",
      "Epoch 282/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5745\n",
      "Epoch 283/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5758\n",
      "Epoch 284/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5731\n",
      "Epoch 285/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5761\n",
      "Epoch 286/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6117 - val_loss: 0.5748\n",
      "Epoch 287/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5761\n",
      "Epoch 288/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6117 - val_loss: 0.5767\n",
      "Epoch 289/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5738\n",
      "Epoch 290/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5732\n",
      "Epoch 291/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5744\n",
      "Epoch 292/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5766\n",
      "Epoch 293/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5752\n",
      "Epoch 294/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5743\n",
      "Epoch 295/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5738\n",
      "Epoch 296/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5766\n",
      "Epoch 297/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5776\n",
      "Epoch 298/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5745\n",
      "Epoch 299/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5741\n",
      "Epoch 300/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5739\n",
      "Epoch 301/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5747\n",
      "Epoch 302/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5759\n",
      "Epoch 303/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5743\n",
      "Epoch 304/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5731\n",
      "Epoch 305/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5765\n",
      "Epoch 306/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5733\n",
      "Epoch 307/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5728\n",
      "Epoch 308/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5743\n",
      "Epoch 309/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5734\n",
      "Epoch 310/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5740\n",
      "Epoch 311/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5744\n",
      "Epoch 312/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5743\n",
      "Epoch 313/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5744\n",
      "Epoch 314/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5763\n",
      "Epoch 315/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5744\n",
      "Epoch 316/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5733\n",
      "Epoch 317/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5760\n",
      "Epoch 318/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5741\n",
      "Epoch 319/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5736\n",
      "Epoch 320/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5744\n",
      "Epoch 321/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5756\n",
      "Epoch 322/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5743\n",
      "Epoch 323/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5738\n",
      "Epoch 324/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5740\n",
      "Epoch 325/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5751\n",
      "Epoch 326/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5764\n",
      "Epoch 327/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5777\n",
      "Epoch 328/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5727\n",
      "Epoch 329/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5760\n",
      "Epoch 330/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5750\n",
      "Epoch 331/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5767\n",
      "Epoch 332/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5738\n",
      "Epoch 333/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5749\n",
      "Epoch 334/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5737\n",
      "Epoch 335/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5743\n",
      "Epoch 336/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5732\n",
      "Epoch 337/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5735\n",
      "Epoch 338/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5736\n",
      "Epoch 339/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5771\n",
      "Epoch 340/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5730\n",
      "Epoch 341/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5745\n",
      "Epoch 342/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5769\n",
      "Epoch 343/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5748\n",
      "Epoch 344/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5745\n",
      "Epoch 345/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5733\n",
      "Epoch 346/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5724\n",
      "Epoch 347/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5736\n",
      "Epoch 348/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5750\n",
      "Epoch 349/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5742\n",
      "Epoch 350/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5733\n",
      "Epoch 351/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5736\n",
      "Epoch 352/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5736\n",
      "Epoch 353/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5737\n",
      "Epoch 354/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5747\n",
      "Epoch 355/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5755\n",
      "Epoch 356/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5746\n",
      "Epoch 357/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5749\n",
      "Epoch 358/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5732\n",
      "Epoch 359/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5735\n",
      "Epoch 360/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5726\n",
      "Epoch 361/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5754\n",
      "Epoch 362/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5731\n",
      "Epoch 363/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5720\n",
      "Epoch 364/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5738\n",
      "Epoch 365/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5758\n",
      "Epoch 366/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5749\n",
      "Epoch 367/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5749\n",
      "Epoch 368/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5729\n",
      "Epoch 369/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5740\n",
      "Epoch 370/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5738\n",
      "Epoch 371/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5726\n",
      "Epoch 372/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5743\n",
      "Epoch 373/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5763\n",
      "Epoch 374/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5747\n",
      "Epoch 375/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5760\n",
      "Epoch 376/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5733\n",
      "Epoch 377/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5742\n",
      "Epoch 378/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5748\n",
      "Epoch 379/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5732\n",
      "Epoch 380/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5726\n",
      "Epoch 381/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5726\n",
      "Epoch 382/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5772\n",
      "Epoch 383/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5757\n",
      "Epoch 384/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5743\n",
      "Epoch 385/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5740\n",
      "Epoch 386/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5741\n",
      "Epoch 387/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5740\n",
      "Epoch 388/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5742\n",
      "Epoch 389/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5737\n",
      "Epoch 390/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5756\n",
      "Epoch 391/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5746\n",
      "Epoch 392/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5747\n",
      "Epoch 393/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5754\n",
      "Epoch 394/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5739\n",
      "Epoch 395/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5737\n",
      "Epoch 396/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5738\n",
      "Epoch 397/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5741\n",
      "Epoch 398/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5745\n",
      "Epoch 399/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5743\n",
      "Epoch 400/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5738\n",
      "Epoch 401/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5748\n",
      "Epoch 402/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5733\n",
      "Epoch 403/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5741\n",
      "Epoch 404/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5749\n",
      "Epoch 405/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5738\n",
      "Epoch 406/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5743\n",
      "Epoch 407/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5752\n",
      "Epoch 408/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5748\n",
      "Epoch 409/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5742\n",
      "Epoch 410/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5747\n",
      "Epoch 411/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5724\n",
      "Epoch 412/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5754\n",
      "Epoch 413/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5733\n",
      "Epoch 414/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5757\n",
      "Epoch 415/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5751\n",
      "Epoch 416/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5760\n",
      "Epoch 417/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5728\n",
      "Epoch 418/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5747\n",
      "Epoch 419/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5738\n",
      "Epoch 420/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5754\n",
      "Epoch 421/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5739\n",
      "Epoch 422/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5739\n",
      "Epoch 423/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5744\n",
      "Epoch 424/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5753\n",
      "Epoch 425/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5746\n",
      "Epoch 426/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5736\n",
      "Epoch 427/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5751\n",
      "Epoch 428/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5733\n",
      "Epoch 429/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5753\n",
      "Epoch 430/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5735\n",
      "Epoch 431/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5758\n",
      "Epoch 432/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6113 - val_loss: 0.5734\n",
      "Epoch 433/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5746\n",
      "Epoch 434/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5730\n",
      "Epoch 435/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5730\n",
      "Epoch 436/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5737\n",
      "Epoch 437/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5729\n",
      "Epoch 438/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5748\n",
      "Epoch 439/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5738\n",
      "Epoch 440/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5745\n",
      "Epoch 441/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5746\n",
      "Epoch 442/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5739\n",
      "Epoch 443/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5742\n",
      "Epoch 444/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5738\n",
      "Epoch 445/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5760\n",
      "Epoch 446/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5749\n",
      "Epoch 447/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5740\n",
      "Epoch 448/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5736\n",
      "Epoch 449/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6113 - val_loss: 0.5732\n",
      "Epoch 450/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5747\n",
      "Epoch 451/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5742\n",
      "Epoch 452/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5754\n",
      "Epoch 453/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5742\n",
      "Epoch 454/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5729\n",
      "Epoch 455/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5748\n",
      "Epoch 456/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5745\n",
      "Epoch 457/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5737\n",
      "Epoch 458/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5732\n",
      "Epoch 459/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5743\n",
      "Epoch 460/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5735\n",
      "Epoch 461/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5741\n",
      "Epoch 462/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5749\n",
      "Epoch 463/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5730\n",
      "Epoch 464/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5738\n",
      "Epoch 465/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5728\n",
      "Epoch 466/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5746\n",
      "Epoch 467/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5737\n",
      "Epoch 468/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5746\n",
      "Epoch 469/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5743\n",
      "Epoch 470/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5758\n",
      "Epoch 471/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5739\n",
      "Epoch 472/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5757\n",
      "Epoch 473/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5743\n",
      "Epoch 474/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5726\n",
      "Epoch 475/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6113 - val_loss: 0.5740\n",
      "Epoch 476/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5743\n",
      "Epoch 477/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5732\n",
      "Epoch 478/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6113 - val_loss: 0.5732\n",
      "Epoch 479/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6113 - val_loss: 0.5725\n",
      "Epoch 480/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6113 - val_loss: 0.5723\n",
      "Epoch 481/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5737\n",
      "Epoch 482/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5745\n",
      "Epoch 483/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6113 - val_loss: 0.5743\n",
      "Epoch 484/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5748\n",
      "Epoch 485/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5730\n",
      "Epoch 486/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5748\n",
      "Epoch 487/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6113 - val_loss: 0.5746\n",
      "Epoch 488/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6113 - val_loss: 0.5731\n",
      "Epoch 489/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5730\n",
      "Epoch 490/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5731\n",
      "Epoch 491/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6113 - val_loss: 0.5743\n",
      "Epoch 492/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5744\n",
      "Epoch 493/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5738\n",
      "Epoch 494/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5741\n",
      "Epoch 495/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6113 - val_loss: 0.5753\n",
      "Epoch 496/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5733\n",
      "Epoch 497/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5743\n",
      "Epoch 498/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5737\n",
      "Epoch 499/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.5747\n",
      "Epoch 500/500\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5755\n"
     ]
    }
   ],
   "source": [
    "with experiment.train():\n",
    "    history = model.fit(x=X_train, y=y_train, batch_size = batch_size, epochs = epochs, \n",
    "                       validation_data=(X_test, y_test), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('rna_pre_treined.h5')\n",
    "# model = load_model('rna_pre_treined.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "5# Predição para o treino\n",
    "y_train_pred = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'web': 'https://www.comet.ml/api/image/download?imageId=ee9edb311c2a4ae0bd778edb50944e8e&experimentKey=3e4cc70aab3f4f7ebda4c90f425a77a7',\n",
       " 'api': 'https://www.comet.ml/api/rest/v1/image/get-image?imageId=ee9edb311c2a4ae0bd778edb50944e8e&experimentKey=3e4cc70aab3f4f7ebda4c90f425a77a7',\n",
       " 'imageId': 'ee9edb311c2a4ae0bd778edb50944e8e'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title('Curva ROC - RNA')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('Proporção Verdadeiro Positivo')\n",
    "plt.xlabel('Proporção Falso Positivo')\n",
    "experiment.log_figure(figure=plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_proba_cutoff = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de confusão para o treino e para o teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensibilidade do treino: 0.766013586924078\n",
      "Especificidade do treino: 0.4257265418596063\n",
      "Acurácia no banco de treino: 0.5526471649128745\n"
     ]
    }
   ],
   "source": [
    "y_train_pred_class = (y_train_pred > optimal_proba_cutoff)*1\n",
    "cm_train = confusion_matrix(y_train, y_train_pred_class, labels = [0,1])\n",
    "sens_train = cm_train[0,0]/(cm_train[0,0] + cm_train[1,0])\n",
    "print('Sensibilidade do treino: '+ str(sens_train))\n",
    "esp_train = cm_train[1,1]/(cm_train[1,1] + cm_train[0,1])\n",
    "print('Especificidade do treino: '+ str(esp_train))\n",
    "\n",
    "acc_train = (cm_train[0,0]+cm_train[1,1])/(cm_train[0,0]+cm_train[0,1]+cm_train[1,0]+cm_train[1,1])\n",
    "print('Acurácia no banco de treino: ' + str(acc_train))\n",
    "\n",
    "experiment.log_confusion_matrix(matrix = cm_train, labels=['Negative', 'Positive'],\n",
    "                               title = 'Matriz de confusão para o banco de treino',\n",
    "                               file_name='treino.json')\n",
    "experiment.log_metrics({'Sensibilidade treino':sens_train,\n",
    "                       'Especificidade treino':esp_train,\n",
    "                       'Acurácia treino':acc_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensibilidade do teste: 0.802990361644287\n",
      "Especificidade do teste: 0.3972129809804783\n",
      "Acurácia no banco de teste: 0.5726932668329177\n"
     ]
    }
   ],
   "source": [
    " 'municipioIBGE'# Matriz de confusão pra teste\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_test_pred_class = (y_test_pred > optimal_proba_cutoff)*1\n",
    "cm_test = confusion_matrix(y_test, y_test_pred_class, labels = [0,1])\n",
    "sens_test = cm_test[0,0]/(cm_test[0,0] + cm_test[1,0])\n",
    "print('Sensibilidade do teste: '+ str(sens_test))\n",
    "esp_test = cm_test[1,1]/(cm_test[1,1] + cm_test[0,1])\n",
    "print('Especificidade do teste: '+ str(esp_test))\n",
    "\n",
    "acc_test = (cm_test[0,0]+cm_test[1,1])/(cm_test[0,0]+cm_test[0,1]+cm_test[1,0]+cm_test[1,1])\n",
    "print('Acurácia no banco de teste: ' + str(acc_test))\n",
    "\n",
    "experiment.log_confusion_matrix(matrix = cm_test, labels=['Negative', 'Positive'],\n",
    "                               title = 'Matriz de confusão para o banco de teste',\n",
    "                               file_name='teste.json')\n",
    "experiment.log_metrics({'Sensibilidade teste':sens_test,\n",
    "                       'Especificidade teste':esp_test,\n",
    "                       'Acurácia teste':acc_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.ml/martinoni/mae5904-rna/3e4cc70aab3f4f7ebda4c90f425a77a7\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     Acurácia teste             : 0.5726932668329177\n",
      "COMET INFO:     Acurácia treino            : 0.5526471649128745\n",
      "COMET INFO:     Especificidade teste       : 0.3972129809804783\n",
      "COMET INFO:     Especificidade treino      : 0.4257265418596063\n",
      "COMET INFO:     Sensibilidade teste        : 0.802990361644287\n",
      "COMET INFO:     Sensibilidade treino       : 0.766013586924078\n",
      "COMET INFO:     train_batch_loss [11000]   : (0.5751281976699829, 0.8854066729545593)\n",
      "COMET INFO:     train_epoch_duration [500] : (0.23733231400001387, 0.7478343180000593)\n",
      "COMET INFO:     train_loss [500]           : (0.6112968325614929, 0.7044581770896912)\n",
      "COMET INFO:     train_val_loss [500]       : (0.5719955563545227, 0.6175786256790161)\n",
      "COMET INFO:     validate_batch_loss [3000] : (0.5483500957489014, 0.6321446895599365)\n",
      "COMET INFO:   Others:\n",
      "COMET INFO:     train_trainable_params : 137\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     Adam_amsgrad       : 1\n",
      "COMET INFO:     Adam_beta_1        : 0.9\n",
      "COMET INFO:     Adam_beta_2        : 0.999\n",
      "COMET INFO:     Adam_decay         : 1\n",
      "COMET INFO:     Adam_epsilon       : 1e-07\n",
      "COMET INFO:     Adam_learning_rate : 0.001\n",
      "COMET INFO:     Optimizer          : Adam\n",
      "COMET INFO:     batch_size         : 1024\n",
      "COMET INFO:     epochs             : 500\n",
      "COMET INFO:     train_Adam_name    : Adam\n",
      "COMET INFO:     train_steps        : 220\n",
      "COMET INFO:   Uploads [count]:\n",
      "COMET INFO:     code                     : 1 (4 KB)\n",
      "COMET INFO:     confusion-matrix [2]     : 2\n",
      "COMET INFO:     environment details      : 1\n",
      "COMET INFO:     figures                  : 1\n",
      "COMET INFO:     filename                 : 1\n",
      "COMET INFO:     git metadata             : 1\n",
      "COMET INFO:     git-patch (uncompressed) : 1 (327 KB)\n",
      "COMET INFO:     installed packages       : 1\n",
      "COMET INFO:     model graph              : 1\n",
      "COMET INFO:     notebook                 : 1\n",
      "COMET INFO:     os packages              : 1\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Uploading stats to Comet before program termination (may take several seconds)\n",
      "COMET INFO: Still uploading\n",
      "COMET INFO: Waiting for completion of the file uploads (may take several seconds)\n",
      "COMET INFO: Still uploading\n"
     ]
    }
   ],
   "source": [
    "experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
